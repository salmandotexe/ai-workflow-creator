from fastapi import APIRouter, Depends, HTTPException
from core.llm_client import LLMClient, get_llm_client
from tasks.workflow_tasks import execute_dynamic_workflow
import json

router = APIRouter()

@router.post("/generate-workflow/")
async def generate_and_execute_workflow(
    user_instruction: dict,
    openai_client: LLMClient = Depends(get_llm_client)
):
    instruction_text = user_instruction.get("instruction")
    if not instruction_text:
        raise HTTPException(status_code=400, detail="Missing instruction text")

    workflow_json = openai_client.generate_workflow(instruction_text)
    try:
        workflow_steps = json.loads(workflow_json)
    except json.JSONDecodeError:
        raise HTTPException(status_code=500, detail="Invalid JSON generated by OpenAI")

    workflow_definition = {"workflow_name": "AI-Generated", "steps": workflow_steps}
    task = execute_dynamic_workflow.delay(workflow_definition)

    return {"task_id": task.id, "workflow": workflow_steps}

@router.post("/run-workflow/")
async def run_workflow(workflow_definition: dict):
    if not workflow_definition.get("steps"):
        raise HTTPException(status_code=400, detail="Invalid Workflow Definition")

    task = execute_dynamic_workflow.delay(workflow_definition)
    return {"task_id": task.id, "status": "submitted"}
